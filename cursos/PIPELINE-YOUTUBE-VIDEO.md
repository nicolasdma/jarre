# Pipeline: YouTube Video ‚Üí Jarre Learning System

> Documento unificado para procesar un video de YouTube de principio a fin.
> Cubre desde la extracci√≥n del transcript hasta los video embeds inline.
> Gold standard: `kz2h-micrograd` (Karpathy: Micrograd ‚Äî backprop from scratch).

---

## Visi√≥n General

```
YouTube Video
    ‚Üì
[FASE 0] An√°lisis del video (chapters, descripci√≥n, estructura)
    ‚Üì
[FASE 1] Extracci√≥n del transcript con timestamps
    ‚Üì
[FASE 2] Traducci√≥n p√°rrafo-por-p√°rrafo EN ‚Üí ES
    ‚Üì
[FASE 3] Generaci√≥n de contenido pedag√≥gico (3 iteraciones)
    ‚Üì
[FASE 4] Setup de base de datos (resource, concepts)
    ‚Üì
[FASE 5] Seed de secciones a Supabase
    ‚Üì
[FASE 6] Mapeo de segmentos de video a headings ‚Üê PROCESO CENTRAL
    ‚Üì
[FASE 7] Artefactos: Advance Organizer, Quizzes, Questions, Exercises
    ‚Üì
[FASE 8] Registro de rutas + Verificaci√≥n
```

**Tiempo estimado por recurso:** Variable seg√∫n duraci√≥n del video y densidad conceptual. kz2h-micrograd (~2.5h video) tom√≥ ~3 sesiones completas.

---

## INPUT REQUERIDO

1. **URL de YouTube** o Video ID
2. **Resource ID:** Convenci√≥n `kz2h-{topic}` para Karpathy, `{keyword}-lecture` para otros
3. **T√≠tulo en espa√±ol**
4. **Fase de estudio** (1-11)

---

## FASE 0: An√°lisis del Video

Antes de extraer nada, analizar el video manualmente. Esto informa todas las decisiones posteriores.

### 0a. Obtener chapters del video

Los chapters de YouTube son la fuente primaria de estructura. Obtenerlos de:

1. **Descripci√≥n del video** ‚Äî Los chapters est√°n listados con timestamps (`00:00:00 intro`, `00:08:08 derivative...`)
2. **YouTube UI** ‚Äî En el player, los chapters aparecen como segmentos en la barra de progreso
3. **Si no hay chapters** ‚Äî Anotar manualmente los cambios de tema mirando el video (buscar transiciones como "now let's...", "next we'll...", slides nuevos)

**Formato de captura:**

```
00:00:00 intro
00:00:25 micrograd overview
00:08:08 derivative of a simple function with one input
00:14:12 derivative of a function with multiple inputs
...
```

Guardar en un comentario dentro del script de seed o en un archivo temporal.

### 0b. Analizar la estructura conceptual

Mirar el video (al menos en 2x) y responder:

- ¬øCu√°les son los 4-6 **temas centrales** del video?
- ¬øEl video sigue un orden pedag√≥gico lineal o salta entre temas?
- ¬øHay partes que son **setup** (mostrar c√≥digo, importar librer√≠as) vs **conceptuales** (explicar por qu√©)?
- ¬øHay demostraciones en vivo donde el instructor escribe c√≥digo?
- ¬øHay momentos de "revelaci√≥n" o eureka que merecen tratamiento especial?

### 0c. Decidir la resegmentaci√≥n tem√°tica

Los chapters del video rara vez coinciden 1:1 con secciones pedag√≥gicas. Decidir:

- **Qu√© chapters se fusionan** (temas relacionados que juntos forman una unidad coherente)
- **Qu√© chapters se dividen** (un chapter largo que cubre m√∫ltiples conceptos)
- **Qu√© orden tem√°tico seguir** (puede diferir del orden cronol√≥gico del video)

**Ejemplo de kz2h-micrograd:**

```
VIDEO (cronol√≥gico):          CONTENIDO (tem√°tico):
1. intro                  ‚Üí   S0: Qu√© es ML (caps 1,2 + cap 13 de PyTorch)
2. micrograd overview     ‚Üí   S1: Value (caps 5, parte de 6)
3. derivative simple      ‚Üí   S2: Derivada Parcial (caps 3,4, parte de 6)
4. derivative multiple    ‚Üí   S3: Backpropagation (caps 7-12, parte de 15-17)
5. Value object           ‚Üí   S4: MLP (caps 14, 15-17, 18-21)
6. manual backprop #1
...21 chapters total
```

Notar: los cap√≠tulos 3-4 (derivadas) aparecen DESPU√âS de 5 (Value) en el video, pero ANTES en el contenido pedag√≥gico. La resegmentaci√≥n prioriza comprensi√≥n gradual sobre orden cronol√≥gico.

---

## FASE 1: Extracci√≥n del Transcript

### Script: `scripts/ingest-youtube.py`

```bash
# Uso b√°sico
python scripts/ingest-youtube.py "https://www.youtube.com/watch?v=VMj-3S1tku0"

# Con opciones
python scripts/ingest-youtube.py VMj-3S1tku0 \
  --resource-id kz2h-micrograd \
  --language en \
  --chunk-size 500
```

**Flags:**

| Flag | Default | Prop√≥sito |
|------|---------|-----------|
| `--resource-id` | `youtube-{VIDEO_ID}` | Override del resource_id |
| `--concept-id` | `to-be-mapped` | Concept ID (se cambia despu√©s) |
| `--language` | `en` | Idioma del transcript |
| `--chunk-size` | `500` | Palabras por chunk |
| `--output-dir` | `scripts/output` | Directorio de salida |

**Qu√© hace el script:**

1. Extrae video ID de URL (soporta youtube.com, youtu.be, embed, bare ID)
2. Obtiene transcript v√≠a `youtube-transcript-api` (prefiere manual sobre auto-generated)
3. Limpia artefactos de auto-caption (`[Music]`, `[Applause]`, stuttering)
4. Segmenta en chunks de ~500 palabras usando silence gaps (>5s) como boundaries
5. Genera JSON con timestamps: `scripts/output/youtube-{VIDEO_ID}-sections.json`

**Output:**

```json
[
  {
    "resource_id": "kz2h-micrograd",
    "concept_id": "to-be-mapped",
    "section_title": "Part 1 (0:00 - 8:08)",
    "sort_order": 0,
    "content_original": "so what is micrograd...",
    "word_count": 487
  }
]
```

**Dependencias:** `pip install youtube-transcript-api`

**Gotcha:** Si el video tiene captions auto-generados, la calidad puede ser baja. Verificar el output manualmente.

---

## FASE 2: Traducci√≥n

### Script: `scripts/translate-chapter.py`

```bash
python scripts/translate-chapter.py scripts/output/youtube-VMj-3S1tku0-sections.json \
  --glossary ml-ai
```

**Flags:**

| Flag | Default | Prop√≥sito |
|------|---------|-----------|
| `--glossary` | `distributed-systems` | Dominio del glosario (`scripts/glossaries/{domain}.json`) |
| `--output-dir` | `scripts/output` | Directorio de salida |

**Qu√© hace:**

1. Divide cada secci√≥n en p√°rrafos (por `\n\n`)
2. Traduce p√°rrafo por p√°rrafo v√≠a DeepSeek V3 con:
   - Glosario t√©cnico inyectado en system prompt
   - Contexto deslizante (√∫ltimos 500 chars de traducci√≥n anterior)
   - Instrucci√≥n expl√≠cita "DO NOT SUMMARIZE" en cada llamada
   - Temperatura 0.15 (muy conservador)
3. Verifica ratio de longitud por p√°rrafo: `0.85 ‚â§ ratio ‚â§ 1.50`
4. Genera `scripts/output/{stem}-translated.json`

**Glosarios disponibles:**
- `scripts/glossaries/distributed-systems.json` (36 t√©rminos)
- `scripts/glossaries/ml-ai.json` (74 t√©rminos)

**Output:** Mismo formato pero con `content_markdown` (ES) y `content_original` (EN) preservado.

**IMPORTANTE:** Este output es la **traducci√≥n fiel** del transcript. NO es el contenido pedag√≥gico final. La Fase 3 lo transforma.

---

## FASE 3: Generaci√≥n de Contenido Pedag√≥gico

> Referencia completa: `cursos/PROMPT-GENERATE-CONTENT.md` + `cursos/CONTENT-QUALITY-STANDARD.md`

### Resumen del proceso (3 iteraciones)

**Iteraci√≥n 1 ‚Äî Conversaci√≥n cruda:**
- Input: transcript traducido
- Output: conversaci√≥n de aprendizaje (~400-600 l√≠neas)
- Guardar en `ml_deep/{nombre}-conversacion-completa.md`
- **Esperar aprobaci√≥n antes de continuar**

**Iteraci√≥n 2 ‚Äî Enrichment pedag√≥gico:**
- Aplicar las 6 operaciones: expandir, insistir, eureka, analog√≠as, repetici√≥n distribuida, explicitar c√≥digo
- Resegmentar en 5 secciones con progresi√≥n: contexto ‚Üí building block ‚Üí mecanismo ‚Üí automatizaci√≥n ‚Üí integraci√≥n
- Output: `scripts/output/{resource-id}-resegmented.json`
- **Producir secci√≥n por secci√≥n, esperar aprobaci√≥n**

**Iteraci√≥n 3 ‚Äî Cross-linking:**
- Agregar links üîó, reglas pr√°cticas, tablas comparativas
- Revisar tono, progresi√≥n, ritmo

### Formato del JSON resegmentado

```json
[
  {
    "resource_id": "kz2h-micrograd",
    "concept_id": "neural-network-fundamentals",
    "section_title": "Qu√© es ML ‚Äî La F√°brica que Aprende Sola",
    "sort_order": 0,
    "content_markdown": "**El cambio de paradigma**\n\nHay una inversi√≥n...\n\n**Micrograd y la clase Value**\n\n..."
  }
]
```

### Los bold headings son la unidad at√≥mica

Dentro de `content_markdown`, cada `**Bold Heading**` (en su propia l√≠nea) define una sub-secci√≥n. Estos headings son la **interfaz de posicionamiento** para video embeds y quizzes inline.

**CR√çTICO:** Los headings deben dise√±arse pensando en qu√© segmentos de video van a mapear a ellos. Cada heading que corresponde a una parte del video debe nombrarse de forma que refleje el concepto cubierto en esa porci√≥n del video.

### M√©tricas de referencia (video corto 1-2hrs)

| M√©trica | Target |
|---------|--------|
| Secciones | 4-6 |
| Chars por secci√≥n | 10K-18K |
| Total | 50K-80K |
| Ratio expansi√≥n vs fuente | 3-5x |

### M√©tricas de referencia (video largo 3-5hrs)

| M√©trica | Target |
|---------|--------|
| Secciones | 4-6 |
| Chars por secci√≥n | 16K-25K |
| Total | 80K-120K |
| Ratio expansi√≥n vs fuente | 2-3x |

---

## FASE 4: Setup de Base de Datos

### 4a. Verificar/crear el resource

```sql
SELECT id, title FROM resources WHERE id = 'kz2h-micrograd';

-- Si no existe:
INSERT INTO resources (id, title, type, phase)
VALUES ('kz2h-micrograd', 'Micrograd: Backprop desde Cero', 'lecture', '2'::study_phase);
```

**Tipo:** Usar `'lecture'` para videos estructurados (aparecen en library principal). El tipo `'video'` se oculta en la vista principal.

### 4b. Crear concepts

Cada secci√≥n mapea a un `concept_id`. Crear migraci√≥n:

```sql
-- supabase/migrations/{timestamp}_{resource_id}_concepts.sql
INSERT INTO concepts (id, name, slug, canonical_definition, phase)
VALUES
  ('neural-network-fundamentals', 'Neural Network Fundamentals', 'neural-network-fundamentals',
   'Core concepts of neural networks including Value objects, computation graphs, and forward passes', '2'::study_phase),
  ('backpropagation-training', 'Backpropagation & Training', 'backpropagation-training',
   'Automatic differentiation via backpropagation and gradient descent training', '2'::study_phase)
ON CONFLICT (id) DO NOTHING;
```

---

## FASE 5: Seed de Secciones

### Script dedicado por recurso

Crear `scripts/seed-{resource-id}-sections.ts`:

```bash
npx tsx scripts/seed-kz2h-micrograd-sections.ts
```

**Qu√© hace:**
1. Lee `scripts/output/{resource-id}-resegmented.json`
2. Valida que `concept_id` de cada secci√≥n existe en DB
3. Limpia dependencias FK (question_bank, inline_quizzes, video_segments) ‚Äî **NO son CASCADE**
4. Borra secciones existentes del mismo resource_id
5. Inserta las nuevas secciones

**Alternativa gen√©rica:**

```bash
npx tsx scripts/seed-sections.ts --from-file scripts/output/{resource-id}-resegmented.json
```

---

## FASE 6: Mapeo de Segmentos de Video a Headings

> **Esta es la fase m√°s cr√≠tica y artesanal del pipeline.**
> No hay automatizaci√≥n posible ‚Äî requiere juicio humano sobre pedagog√≠a.

### El Concepto

Cada secci√≥n del contenido pedag√≥gico tiene bold headings (`**Heading**`). Algunos de esos headings corresponden a partes espec√≠ficas del video. El objetivo es **embeber el clip exacto del video debajo del heading correspondiente**, para que el estudiante lea el heading, vea el video de esa parte, y luego lea la explicaci√≥n expandida.

**Flujo en la UI:**

```
**Bold Heading**           ‚Üê T√≠tulo del concepto
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  ‚ñ∂ YouTube Embed     ‚îÇ   ‚Üê Video clip (start ‚Üí end)
‚îÇ  0:32:10 ‚Äì 0:51:10   ‚îÇ
‚îÇ  ¬∑ Backprop manual    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
Contenido expandido...     ‚Üê Texto pedag√≥gico enriquecido
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Quiz inline          ‚îÇ   ‚Üê Evaluaci√≥n post-lectura
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Prerrequisitos

Para esta fase necesit√°s tener:

1. ‚úÖ Los **chapters del video** con timestamps (de FASE 0)
2. ‚úÖ El **contenido resegmentado** con todos los bold headings (de FASE 3)
3. ‚úÖ Las **secciones seeded** en Supabase (de FASE 5) ‚Äî necesit√°s los `section_id` UUIDs

### El Proceso Paso a Paso

#### Paso 1: Listar los chapters del video

Copiar los chapters de la descripci√≥n de YouTube con timestamps exactos:

```
00:00:00 intro
00:00:25 micrograd overview
00:08:08 derivative of a simple function with one input
00:14:12 derivative of a function with multiple inputs
00:19:09 starting the core Value object and its visualization
00:32:10 manual backpropagation example #1: simple expression
00:51:10 preview of a single optimization step
00:52:52 manual backpropagation example #2: a neuron
01:09:02 implementing the backward function for each operation
...
```

Calcular `endSeconds` de cada chapter: es el `startSeconds` del siguiente chapter.

#### Paso 2: Listar todos los bold headings del contenido

Para cada secci√≥n, extraer los headings:

```
SECCI√ìN 0: Qu√© es ML ‚Äî La F√°brica que Aprende Sola
  - El cambio de paradigma
  - Los ingredientes del ML
  - La f√°brica con perillas
  - Micrograd y la clase Value
  - De micrograd a PyTorch

SECCI√ìN 1: Value ‚Äî Un N√∫mero con Memoria
  - Construyendo Value
  - El DAG
  - El gradiente
  ...
```

#### Paso 3: Clasificar cada heading

Para CADA heading, decidir:

| Clasificaci√≥n | Criterio | Acci√≥n |
|---------------|----------|--------|
| **Video directo** | El heading corresponde claramente a un chapter o porci√≥n del video | Mapear chapter(s) ‚Üí heading con timestamps |
| **Editorial** | El heading es contenido agregado por el enrichment pedag√≥gico (analog√≠as, reglas pr√°cticas, s√≠ntesis, explicaci√≥n de c√≥digo detallada) | No asignar video ‚Äî skip |

**Se√±ales de heading editorial (sin video):**
- Empieza con "Regla pr√°ctica:" ‚Äî es un mnemot√©cnico sintetizado
- Es una explicaci√≥n de m√©todo Python (`__init__`, `__call__`, `parameters`) ‚Äî nivel de detalle que el video no cubre
- Es una analog√≠a o met√°fora ("La f√°brica con perillas") ‚Äî narrativa agregada
- Es una s√≠ntesis comparativa (tablas tanh vs ReLU) ‚Äî contenido expandido

**Se√±ales de heading con video:**
- Nombra un concepto que el instructor explica directamente en el video
- Corresponde a un step del flujo que se demuestra en vivo
- Involucra c√≥digo que el instructor escribe en pantalla

#### Paso 4: Para cada heading con video, determinar timestamps

Este es el paso m√°s delicado. Hay 5 estrategias de mapeo:

##### Estrategia 1: Mapeo directo (1 chapter ‚Üí 1 heading)

El caso m√°s simple. Un chapter del video corresponde exactamente a un heading.

```typescript
{
  sectionTitle: 'La Derivada Parcial ‚Äî El Momento Eureka',
  positionAfterHeading: 'PARA. QUE. ES. ESTO.',
  startSeconds: 488,     // 00:08:08 ‚Äî inicio del chapter
  endSeconds: 852,       // 00:14:12 ‚Äî inicio del siguiente chapter
  label: 'La derivada: definici√≥n, l√≠mite y evaluaci√≥n num√©rica',
}
```

**Cu√°ndo usar:** El chapter cubre UN tema que mapea limpiamente a UN heading.

##### Estrategia 2: Fusi√≥n (N chapters ‚Üí 1 heading)

Varios chapters del video se combinan en un solo heading porque juntos forman una unidad tem√°tica.

```typescript
{
  // Chapters 1+2: "intro" + "micrograd overview"
  positionAfterHeading: 'Micrograd y la clase Value',
  startSeconds: 0,       // 00:00:00 ‚Äî inicio de chapter 1
  endSeconds: 488,       // 00:08:08 ‚Äî inicio de chapter 3 (fin de chapter 2)
  label: 'Intro: qu√© es micrograd, Value y expression graphs',
}
```

**Cu√°ndo usar:** Chapters cortos y adyacentes que cubren el mismo tema. T√≠pico con "intro" + primer chapter, o "walkthrough" + "conclusion".

##### Estrategia 3: Divisi√≥n (1 chapter ‚Üí N headings)

Un chapter largo cubre m√∫ltiples conceptos. Se crean m√∫ltiples segmentos con timestamps parciales.

```typescript
// Chapter 5: "starting the core Value object" (19:09 ‚Üí 32:10)
// Se divide en 2 headings:

{
  positionAfterHeading: 'Construyendo Value',
  startSeconds: 1149,    // 00:19:09 ‚Äî inicio del chapter
  endSeconds: 1930,      // 00:32:10 ‚Äî fin del chapter
  label: 'Clase Value: __add__, __mul__, _prev, _op, visualizaci√≥n',
},
{
  positionAfterHeading: 'El DAG',
  startSeconds: 1440,    // ~24:00 ‚Äî graphviz se introduce a mitad del chapter
  endSeconds: 1930,      // 00:32:10 ‚Äî fin del chapter
  label: 'El DAG: visualizaci√≥n con Graphviz y draw_dot',
}
```

**Cu√°ndo usar:** Un chapter de >10 minutos que introduce m√∫ltiples conceptos. El timestamp de inicio del segundo segmento es APROXIMADO ‚Äî mirar el video para encontrar el punto de transici√≥n.

**C√ìMO encontrar el punto de corte:**
1. Abrir el video en YouTube
2. Navegar al chapter
3. Buscar el momento donde el instructor cambia de tema, introduce un nuevo concepto, o muestra algo nuevo en pantalla
4. Anotar el timestamp (redondear a minutos est√° OK para segmentos >5min)

##### Estrategia 4: Rearreglo tem√°tico (chapters no-adyacentes ‚Üí mismo heading o secci√≥n)

Chapters que est√°n dispersos en el video pero pertenecen al mismo tema pedag√≥gico.

```typescript
// Chapter 13 (01:39:31) aparece en Secci√≥n 0, NO en orden cronol√≥gico
{
  sectionTitle: 'Qu√© es ML ‚Äî La F√°brica que Aprende Sola',  // Secci√≥n 0
  positionAfterHeading: 'De micrograd a PyTorch',
  startSeconds: 5971,    // 01:39:31 ‚Äî chapter 13, cronol√≥gicamente mucho despu√©s
  endSeconds: 6235,      // 01:43:55
  label: 'Demo PyTorch: mismos resultados que micrograd',
}
```

**Cu√°ndo usar:** Cuando el video tiene un momento posterior que complementa un tema de la introducci√≥n. El contenido resegmentado agrupa temas, no sigue cronolog√≠a.

##### Estrategia 5: Reutilizaci√≥n (1 chapter ‚Üí N headings en distintas secciones)

El mismo video se embebe en dos contextos diferentes, cada uno enfatizando un aspecto distinto.

```typescript
// Chapter 8 ("manual backprop #2") reutilizado:

// Contexto 1: Forward y backward completo
{
  sectionTitle: 'Backpropagation y la Chain Rule',
  positionAfterHeading: 'Forward y backward a mano',
  startSeconds: 3070,    // 00:51:10
  endSeconds: 4142,      // 01:09:02
  label: 'Neurona con tanh: forward pass y backprop manual',
},

// Contexto 2: Foco espec√≠fico en tanh
{
  sectionTitle: 'Backpropagation y la Chain Rule',
  positionAfterHeading: 'Backprop con tanh',
  startSeconds: 3172,    // 00:52:52 (ligeramente diferente)
  endSeconds: 4142,      // 01:09:02
  label: 'Implementando tanh y backprop completo de una neurona',
}
```

**Cu√°ndo usar:** Cuando un chapter es tan rico que dos headings diferentes se benefician de verlo. Cada instancia puede tener timestamps ligeramente distintos para enfocar la porci√≥n m√°s relevante.

#### Paso 5: Escribir el script de seed

Crear `scripts/seed-video-segments-{resource-id}.ts`:

```typescript
import { createClient } from '@supabase/supabase-js';
import * as dotenv from 'dotenv';
import { resolve } from 'path';

dotenv.config({ path: resolve(__dirname, '../.env.local') });

const supabase = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL!,
  process.env.SUPABASE_SECRET_KEY!
);

const RESOURCE_ID = '{resource-id}';
const YOUTUBE_VIDEO_ID = '{video-id}';

interface VideoSegmentDef {
  sectionTitle: string;          // DEBE coincidir EXACTAMENTE con section_title en DB
  positionAfterHeading: string;  // DEBE coincidir EXACTAMENTE con **heading** en content_markdown
  sortOrder: number;
  startSeconds: number;
  endSeconds: number;
  label: string;                 // Descripci√≥n breve del clip
}

const SEGMENTS: VideoSegmentDef[] = [
  // Pegar los chapters de YouTube como comentario de referencia:
  //
  // 00:00:00 intro
  // 00:00:25 topic overview
  // ...
  //
  // Luego los segmentos:
  {
    sectionTitle: '{T√≠tulo exacto de la secci√≥n}',
    positionAfterHeading: '{Texto exacto del **heading**}',
    sortOrder: 0,
    startSeconds: 0,
    endSeconds: 488,
    label: 'Descripci√≥n del contenido del clip',
  },
  // ...
];

async function main() {
  // 1. Fetch section IDs
  const { data: sections, error: sectionsError } = await supabase
    .from('resource_sections')
    .select('id, section_title')
    .eq('resource_id', RESOURCE_ID)
    .order('sort_order');

  if (sectionsError || !sections?.length) {
    console.error('Failed to fetch sections:', sectionsError);
    process.exit(1);
  }

  const sectionMap = new Map(sections.map((s) => [s.section_title, s.id]));

  // 2. Delete existing video segments
  const sectionIds = sections.map((s) => s.id);
  await supabase.from('video_segments').delete().in('section_id', sectionIds);

  // 3. Insert new segments
  const rows = SEGMENTS.map((seg) => {
    const sectionId = sectionMap.get(seg.sectionTitle);
    if (!sectionId) throw new Error(`Section not found: "${seg.sectionTitle}"`);
    return {
      section_id: sectionId,
      position_after_heading: seg.positionAfterHeading,
      sort_order: seg.sortOrder,
      youtube_video_id: YOUTUBE_VIDEO_ID,
      start_seconds: seg.startSeconds,
      end_seconds: seg.endSeconds,
      label: seg.label,
    };
  });

  const { error: insertError } = await supabase.from('video_segments').insert(rows);
  if (insertError) {
    console.error('Failed to insert:', insertError);
    process.exit(1);
  }

  console.log(`Inserted ${rows.length} video segments across ${sections.length} sections`);
}

main();
```

**Ejecutar:**

```bash
npx tsx scripts/seed-video-segments-{resource-id}.ts
```

### Reglas del Matching (CR√çTICAS)

| Regla | Detalle |
|-------|---------|
| `sectionTitle` | Debe coincidir **exactamente** con `section_title` en la tabla `resource_sections` |
| `positionAfterHeading` | Debe coincidir **exactamente** con el texto dentro de `**...**` en el `content_markdown` |
| Case-sensitive | `"El DAG"` ‚â† `"el dag"` |
| Sin trim | Sin espacios extra al inicio/final |
| Silent skip | Si no matchea, el video simplemente no se renderiza (sin error) |

### Orden de Renderizado en la UI

Para cada heading en el contenido:

```
1. **Bold Heading**          ‚Üê se renderiza como t√≠tulo
2. [Video Embed]             ‚Üê SI hay video_segment con positionAfterHeading == heading
3. Contenido markdown        ‚Üê texto pedag√≥gico debajo del heading
4. [Inline Quiz]             ‚Üê SI hay inline_quiz con positionAfterHeading == heading
```

El video va ANTES del contenido textual. La idea: "mir√° esta parte del video, y despu√©s le√© la explicaci√≥n expandida".

### Tabla de Decisi√≥n: ¬øEste heading lleva video?

```
¬øEl instructor cubre este concepto         ‚î¨‚îÄ‚îÄ S√ç ‚Üí ¬øEs un chapter completo?
  directamente en el video?                 ‚îÇ         ‚îú‚îÄ‚îÄ S√ç ‚Üí Estrategia 1 (mapeo directo)
                                            ‚îÇ         ‚îî‚îÄ‚îÄ NO ‚Üí ¬øEs parte de un chapter largo?
                                            ‚îÇ                   ‚îú‚îÄ‚îÄ S√ç ‚Üí Estrategia 3 (divisi√≥n)
                                            ‚îÇ                   ‚îî‚îÄ‚îÄ Es varios chapters juntos
                                            ‚îÇ                             ‚Üí Estrategia 2 (fusi√≥n)
                                            ‚îÇ
                                            ‚îî‚îÄ‚îÄ NO ‚Üí ¬øEs contenido editorial?
                                                      ‚îú‚îÄ‚îÄ Regla pr√°ctica ‚Üí SKIP
                                                      ‚îú‚îÄ‚îÄ Analog√≠a/met√°fora ‚Üí SKIP
                                                      ‚îú‚îÄ‚îÄ Explicaci√≥n de c√≥digo detallada ‚Üí SKIP
                                                      ‚îú‚îÄ‚îÄ Tabla comparativa ‚Üí SKIP
                                                      ‚îî‚îÄ‚îÄ S√≠ntesis/resumen ‚Üí SKIP
```

### Estad√≠sticas del Gold Standard (kz2h-micrograd)

| M√©trica | Valor |
|---------|-------|
| Chapters de YouTube | 21 |
| Headings totales en contenido | 54 |
| Headings con video | 22 (42%) |
| Headings editoriales (sin video) | 32 (58%) |
| Cap√≠tulos fusionados | 9 ‚Üí 5 segmentos |
| Cap√≠tulos divididos | 4 ‚Üí 10 segmentos |
| Cap√≠tulos reutilizados | 1 (chapter 8 en 2 headings) |

**Distribuci√≥n por secci√≥n:**

| Secci√≥n | Headings | Con Video | % |
|---------|----------|-----------|---|
| S0: Qu√© es ML | 5 | 2 | 40% |
| S1: Value | 3 | 3 | 100% |
| S2: Derivada | 6 | 4 | 67% |
| S3: Backprop | 16 | 9 | 56% |
| S4: MLP | 20 | 5 | 25% |

**Patr√≥n:** Las secciones m√°s conceptuales/de implementaci√≥n (S1, S2) tienen mayor % de video. Las secciones con m√°s contenido editorial expandido (S4) tienen menor %.

### Tabla de video_segments en DB

```sql
CREATE TABLE video_segments (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  section_id UUID NOT NULL REFERENCES resource_sections(id) ON DELETE CASCADE,
  position_after_heading TEXT NOT NULL,    -- Matching exacto con **heading**
  sort_order INTEGER NOT NULL DEFAULT 0,  -- Orden dentro del mismo heading
  youtube_video_id TEXT NOT NULL,          -- ID de 11 chars de YouTube
  start_seconds INTEGER NOT NULL,
  end_seconds INTEGER NOT NULL,
  label TEXT,                              -- Descripci√≥n breve (opcional)
  created_at TIMESTAMPTZ DEFAULT NOW()
);
```

- RLS: Public read (contenido no es user-specific)
- Index: `(section_id, sort_order)`
- Cascade: `ON DELETE CASCADE` desde `resource_sections`

### Tipo TypeScript

```typescript
interface VideoSegment {
  id: string;
  sectionId: string;
  positionAfterHeading: string;
  sortOrder: number;
  youtubeVideoId: string;
  startSeconds: number;
  endSeconds: number;
  label: string | null;
}
```

---

## FASE 7: Artefactos

> Referencia completa: `cursos/TEMPLATE-CONTENT-GENERATION.md`

### 7a. Advance Organizer (TSX)

Componente visual para el paso ACTIVATE del flujo de aprendizaje.

**Archivo:** `src/app/learn/[resourceId]/{resource-id}.tsx`

5 secciones numeradas con: analog√≠a box, grid comparativo, insight clave, mnemot√©cnico, pregunta final. Ver `cursos/TEMPLATE-CONTENT-GENERATION.md` Paso 2 para estructura completa.

### 7b. Inline Quizzes

**Archivo:** `scripts/seed-inline-quizzes-{resource-id}.ts`

- 12-20 quizzes totales (2-4 por secci√≥n)
- Mix: ~35% MC, ~30% TF, ~35% MC2
- `positionAfterHeading` sigue la MISMA convenci√≥n que video segments
- Los quizzes van DESPU√âS del contenido, los videos van ANTES

**Ejecutar:** `npx tsx scripts/seed-inline-quizzes-{resource-id}.ts`

### 7c. Reading Questions

**Archivo:** `src/app/learn/[resourceId]/reading-questions.ts`

6-7 preguntas: 2 why, 2 tradeoff, 1 connection, 1 design_decision, 1 error_detection.

### 7d. Ejercicios Interactivos

**Archivo:** `src/data/exercises/{resource-id}-exercises.ts`

3 ejercicios: 1 sequence, 1 label o connect, 1 sequence o connect.

### 7e. Playground (opcional)

**Directorio:** `src/app/playground/{name}/`

3 archivos: page.tsx, {name}-playground.tsx, lesson-guide.tsx.

---

## FASE 8: Registro y Verificaci√≥n

### 8a. Registrar rutas

En `src/app/learn/[resourceId]/page.tsx`:

```tsx
// 1. Import
import { KZ2HMicrograd } from './kz2h-micrograd';

// 2. PRACTICAL_ROUTES
'kz2h-micrograd': { label: 'Playground', href: '/playground/micrograd' },

// 3. EXPLANATION_COMPONENTS
'kz2h-micrograd': () => <KZ2HMicrograd />,
```

### 8b. Verificaci√≥n

```bash
# TypeScript compila
npx tsc --noEmit

# Dev server funciona
npm run dev

# Verificar en browser:
# 1. /library ‚Üí el recurso aparece en la fase correcta
# 2. /learn/{resource-id} ‚Üí las secciones se renderizan
# 3. Los videos aparecen debajo de los headings correctos
# 4. Los quizzes aparecen despu√©s del contenido
# 5. El advance organizer se muestra en el paso ACTIVATE
```

---

## Tracking de Progreso

Actualizar la tabla en `BACKLOG.md`:

| Resource | Transcript | Translate | Resegment | TSX | Questions | Quizzes | Exercises | Video Segments |
|----------|-----------|-----------|-----------|-----|-----------|---------|-----------|----------------|
| kz2h-micrograd | x | x | x | x | x | x | x | x |
| kz2h-makemore-bigram | - | - | - | - | - | - | - | - |

---

## Orden de Ejecuci√≥n √ìptimo

```
[FASE 0: An√°lisis]
    ‚Üì
[FASE 1: Transcript] ‚Üí [FASE 2: Traducci√≥n]
    ‚Üì
[FASE 3: Contenido pedag√≥gico] ‚Üê iterativo, con aprobaciones
    ‚Üì
[FASE 4: DB Setup]
    ‚Üì
[FASE 5: Seed secciones]
    ‚Üì (en paralelo)
    ‚îú‚îÄ‚îÄ [FASE 6: Video segments]    ‚Üê requiere secciones seeded + headings finales
    ‚îú‚îÄ‚îÄ [FASE 7b: Inline quizzes]   ‚Üê requiere secciones seeded + headings finales
    ‚îú‚îÄ‚îÄ [FASE 7a: Advance organizer] ‚Üê independiente
    ‚îú‚îÄ‚îÄ [FASE 7c: Reading questions] ‚Üê independiente
    ‚îú‚îÄ‚îÄ [FASE 7d: Ejercicios]       ‚Üê independiente
    ‚îî‚îÄ‚îÄ [FASE 7e: Playground]       ‚Üê independiente
    ‚Üì
[FASE 8: Registro + Verificaci√≥n]
```

**Dependencias cr√≠ticas:**
- FASE 6 y 7b dependen de FASE 5 (necesitan `section_id` UUIDs)
- FASE 6 y 7b dependen de los headings exactos del contenido (FASE 3)
- Todo lo dem√°s puede paralelizarse despu√©s de FASE 5

---

## Checklist Completa por Recurso

```
‚ñ° FASE 0: An√°lisis del video
  ‚ñ° Obtener chapters de YouTube con timestamps
  ‚ñ° Analizar estructura conceptual (mirar video)
  ‚ñ° Decidir resegmentaci√≥n tem√°tica (5 secciones)

‚ñ° FASE 1: Transcript
  ‚ñ° python scripts/ingest-youtube.py {URL}
  ‚ñ° Verificar output: palabras, segmentos, duraci√≥n

‚ñ° FASE 2: Traducci√≥n
  ‚ñ° python scripts/translate-chapter.py {json} --glossary ml-ai
  ‚ñ° Verificar ratios de longitud (0.85-1.50)

‚ñ° FASE 3: Contenido pedag√≥gico
  ‚ñ° Iteraci√≥n 1: Conversaci√≥n cruda ‚Üí aprobaci√≥n
  ‚ñ° Iteraci√≥n 2: Enrichment ‚Üí 5 secciones ‚Üí aprobaci√≥n por secci√≥n
  ‚ñ° Iteraci√≥n 3: Cross-linking ‚Üí revisi√≥n final
  ‚ñ° Output: scripts/output/{resource-id}-resegmented.json

‚ñ° FASE 4: DB Setup
  ‚ñ° Resource existe en tabla resources
  ‚ñ° Concepts creados con migraci√≥n
  ‚ñ° Migraci√≥n aplicada

‚ñ° FASE 5: Seed secciones
  ‚ñ° npx tsx scripts/seed-{resource-id}-sections.ts
  ‚ñ° Verificar secciones en Supabase

‚ñ° FASE 6: Video segments ‚Üê PROCESO CENTRAL
  ‚ñ° Listar chapters de YouTube con timestamps
  ‚ñ° Listar todos los bold headings del contenido
  ‚ñ° Clasificar cada heading: video directo vs editorial
  ‚ñ° Para cada heading con video, determinar timestamps (5 estrategias)
  ‚ñ° Escribir script seed-video-segments-{resource-id}.ts
  ‚ñ° Ejecutar: npx tsx scripts/seed-video-segments-{resource-id}.ts
  ‚ñ° Verificar en UI: videos aparecen debajo de headings correctos

‚ñ° FASE 7: Artefactos
  ‚ñ° 7a: Advance Organizer TSX
  ‚ñ° 7b: Inline Quizzes (12-20, seed script)
  ‚ñ° 7c: Reading Questions (6-7)
  ‚ñ° 7d: Ejercicios (3)
  ‚ñ° 7e: Playground (opcional)

‚ñ° FASE 8: Verificaci√≥n
  ‚ñ° npx tsc --noEmit
  ‚ñ° Registrar en page.tsx (import, PRACTICAL_ROUTES, EXPLANATION_COMPONENTS)
  ‚ñ° Verificar en browser: library ‚Üí learn ‚Üí activate ‚Üí sections ‚Üí videos ‚Üí quizzes
  ‚ñ° Actualizar BACKLOG.md
```
